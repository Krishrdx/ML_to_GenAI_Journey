{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM588W+pnNc8jBeAJ4sOLtD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishrdx/ML_to_GenAI_Journey/blob/main/Month_01_Foundations/Week_01_NumPy/Day_04_NumPy_Linear_Algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Day 04 The Matrix Algebra"
      ],
      "metadata": {
        "id": "jGW7Lokhx75Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fXNjIxyHxAgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f566b77-6937-4ab9-e3ea-c00d0389dc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n",
            "[[22 28]\n",
            " [49 64]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "ab = np.array([2,4,5])\n",
        "bc = np.array([3,4,6])\n",
        "\n",
        "print(np.dot(ab, bc))\n",
        "\n",
        "a = np.array([[1,2,3],[4,5,6]])\n",
        "b = np.array([[1,2],[3,4],[5,6]])\n",
        "\n",
        "adotb = np.dot(a,b)\n",
        "\n",
        "print(adotb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used in:\n",
        "\n",
        "similarity\n",
        "\n",
        "- Dot product = how similar two vectors are.\n",
        "\n",
        "If two vectors point in the same direction ‚Üí large dot product,\n",
        "If opposite ‚Üí negative,\n",
        "If perpendicular ‚Üí dot = 0.\n",
        "\n",
        "attention scores\n",
        "\n",
        "cosine similarity"
      ],
      "metadata": {
        "id": "Ud2hlBNQ0bSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2],\n",
        "              [3,4]])\n",
        "\n",
        "y = np.array([[5,6],\n",
        "              [7,8]])\n",
        "\n",
        "print(np.matmul(x,y))\n",
        "print(x@y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrpG6D910b4O",
        "outputId": "c1c40cff-7c50-4b27-9245-99ef2988ddba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 22]\n",
            " [43 50]]\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** *Shape Rule: *(m √ó n) @ (n √ó p) = (m √ó p)**\n",
        "\n",
        "Otherwise ‚Üí ‚ùå Error"
      ],
      "metadata": {
        "id": "TfE1vO171XPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSPOSE - Important\n",
        "\n",
        "mat = np.array([[1,2,3],[4,5,6]])\n",
        "transpose = mat.T\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQdiJdI11Ybg",
        "outputId": "d78857d5-067e-4154-c0e1-9e0e3a50e774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used in:\n",
        "\n",
        "gradients\n",
        "\n",
        "covariance matrices\n",
        "\n",
        "attention mechanisms"
      ],
      "metadata": {
        "id": "TsryMW6O2Cvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identity and Inverse Matrix:\n",
        "\n",
        "Identity = np.eye(4)\n",
        "\n",
        "print(Identity)\n",
        "\n",
        "demo_mat = np.array([[-18,-2,-53],[4,5,-6],[70,-18,10]])\n",
        "\n",
        "Inverse = np.linalg.inv(demo_mat) # it only exists when determinant of this matrix is NOT equals to ZERO\n",
        "\n",
        "print(Inverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiPkBz2_2GmP",
        "outputId": "6c290427-1d52-4449-b8b2-749df7af510a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "[[-0.00238389  0.04003288  0.01138512]\n",
            " [-0.0189067   0.14508837 -0.01315249]\n",
            " [-0.01734484 -0.01907111 -0.00337032]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Norm = size / length / magnitude of a vector."
      ],
      "metadata": {
        "id": "VhQweaOUxY1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMS - L2 Norms (most used) L2 regularization penalizes large weights smoothly, preventing overfitting and making the model generalize better.\n",
        "\n",
        "v = np.array([5,6])\n",
        "\n",
        "norm = np.linalg.norm(v)\n",
        "\n",
        "print(norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLNDmHTe2dwi",
        "outputId": "a1e4659f-6e68-4732-9cae-41002262400c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.810249675906654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used In:\n",
        "\n",
        "regularization\n",
        "\n",
        "gradient clipping\n",
        "\n",
        "similarity metrics"
      ],
      "metadata": {
        "id": "2sMO2djQ4MUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Connections\n",
        "1. Linear Regression\n",
        "\n",
        "y = X @ w + b\n",
        "\n",
        "2. Neural Network\n",
        "\n",
        "y = X @ w + b\n",
        "\n",
        "3. GEN AI\n",
        "\n",
        "Scores = Q @ K.T"
      ],
      "metadata": {
        "id": "6VnN0t2z4x-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = np.arange(2,66,5)\n",
        "\n",
        "v2 = np.arange(4,55,4)\n",
        "\n",
        "print(v1)\n",
        "print(v2)\n",
        "\n",
        "v1dotv2 = np.dot(v1,v2) # The shapes should be same before the product.\n",
        "\n",
        "print(v1dotv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyVvYl2K4JJk",
        "outputId": "cf203cce-3f8b-4a5c-eec5-9afbe962a365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2  7 12 17 22 27 32 37 42 47 52 57 62]\n",
            "[ 4  8 12 16 20 24 28 32 36 40 44 48 52]\n",
            "15288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[3,6],\n",
        "              [2,9],\n",
        "              [4,4]])\n",
        "\n",
        "y = np.array([[1,2,3,4],\n",
        "              [6,5,4,9]])\n",
        "\n",
        "xmatmuly = x@y # np.matmul(x,y)\n",
        "\n",
        "print(xmatmuly)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi-XrWig5y-d",
        "outputId": "1b3ece3a-4c6c-42ba-d457-fdaca9831ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[39 36 33 66]\n",
            " [56 49 42 89]\n",
            " [28 28 28 52]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([[5,6],\n",
        "             [7,9],\n",
        "             [9,0]])\n",
        "\n",
        "norm = np.linalg.norm(v)\n",
        "\n",
        "print(norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV7K9Txm6dAz",
        "outputId": "fabcf0dc-97ea-4797-97cc-c5a9918d0333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.492422502470642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why matrix multiplication is order-sensitive?\n",
        "- Because matrix multiplication is NOT commutative. A√óB != B√óA\n",
        "\n",
        "2. Why inverse is rarely used in deep learning? (slow + unstable + useless for training)\n",
        "- 1. Computationally expensive\n",
        "Inverse of an n√ón matrix has ~O(n¬≥) complexity ‚Üí very slow for large layers.\n",
        "\n",
        "- 2. Numerically unstable\n",
        "\n",
        "If the matrix is close to singular:\n",
        "inverse becomes huge\n",
        "gradients explode\n",
        "training breaks\n",
        "\n",
        "- 3. We don‚Äôt need the exact inverse\n",
        "\n",
        "Optimization (SGD, Adam, RMSProp‚Ä¶) works by gradients, not by solving exact equations.\n",
        "Instead of:\n",
        "ùëä=ùëã‚àí1ùëåW=X‚àí1Y\n",
        "Deep learning uses:\n",
        "ùëä=ùëä‚àíùúÇ‚ãÖ‚àá\n",
        "W=W‚àíŒ∑‚ãÖ‚àá\n",
        "- 4. Better, more stable alternatives exist\n",
        "Cholesky\n",
        "QR\n",
        "Pseudo-inverse\n",
        "Gradient descent steps\n",
        "\n",
        "So, inverse is avoided unless absolutely necessary.\n",
        "3. Why attention uses dot products?\n",
        "\n",
        "- Dot product gives similarity FAST, -- score=Q‚ãÖKT\n",
        "Dot product measures how aligned two vectors are.\n",
        "Large dot ‚Üí strong attention\n",
        "Small dot ‚Üí weak attention\n",
        "\n",
        "Dot product is extremely efficient on GPUs-- Dot products = matrix multiplication.\n",
        "Matrix multiplication = optimized, parallelized, vectorized.\n",
        "\n",
        "Dot product captures BOTH angle and magnitude."
      ],
      "metadata": {
        "id": "PP-PLnmD8oBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = [3, 4]\n",
        "\n",
        "norm = np.linalg.norm(v)\n",
        "print(norm)"
      ],
      "metadata": {
        "id": "bhVI5r7v8naT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6751f8cb-188e-4e29-eff5-a2c190790f91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZEkOPf52iKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [5, 0 , -2]\n",
        "\n",
        "print(np.linalg.norm(x))"
      ],
      "metadata": {
        "id": "JjwxPHEa8jWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710514de-726c-476b-a38a-0adb12ab7a64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.385164807134504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 encourages sparsity because its gradient is constant and pushes small weights to exactly zero.\n",
        "\n",
        "L2 does NOT create sparsity.\n",
        "L1 does.\n",
        "\n",
        "‚úî L1 ‚Üí sparse weights\n",
        "‚úî L1 ‚Üí feature selection\n",
        "‚úî L1 ‚Üí many zeros"
      ],
      "metadata": {
        "id": "XegEtY0T2Pwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use L2 normalization because:\n",
        "\n",
        "Dot product depends on magnitude, but cosine similarity depends only on direction.\n",
        "L2 normalization makes all vectors unit length, so similarity is determined only by angle."
      ],
      "metadata": {
        "id": "ulmmqETz2hIO"
      }
    }
  ]
}